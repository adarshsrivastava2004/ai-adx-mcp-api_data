# backend/query_planner.py
import requests
import re
import logging
from backend.config import OLLAMA_CHAT_URL, MODEL


# Setup Logger (Production Standard)
logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# ENTERPRISE SYSTEM PROMPT (OPTIMIZED)
# Changes:
# 1. Enforced Case Insensitivity (=~)
# 2. Added "Performance First" rule (Time filters first)
# 3. Explicitly allowed 'let' statements
# ---------------------------------------------------------------------------

SYSTEM_PROMPT = """
You are a Principal Data Engineer and Azure Data Explorer (KQL) expert.

Your task is to convert natural language user requests into HIGH-PERFORMANCE, PRODUCTION-GRADE KQL queries optimized for very large datasets.

You must strictly follow all rules below. Any violation is considered incorrect output.


# 1. DATABASE SCHEMA

Table: API_gateway

Use exact column names (including typos). DO NOT fix spelling mistakes.

| Column Name                               | Type   | Description / Mapping Logic                                     |
|:------------------------------------------|:-------|:----------------------------------------------------------------|
| httpSessionID                             | string | Unique session tracker                                          |
| token                                     | string | **SENSITIVE**. Auth token. Use only if requested.               |
| source                                    | string | Source system identifier                                       |
| topicInBound                              | string | Inbound Kafka topic                                             |
| topicOutBound                             | string | Outbound Kafka topic                                            |
| topicReBound                              | string | Rebound Kafka topic                                             |
| sourcePOD                                 | string | The server handling the request                                 |
| messageReceivedTimeStamp                  | long   | **DEFAULT TIME COLUMN**. Unix Timestamp (ms).                   |
| messagePutIntoKafakTimeStamp              | long   | ACTUAL COLUMN NAME (typo in DB - DO NOT FIX)                    |
| messageReadFromKafakTimeStamp             | long   | ACTUAL COLUMN NAME (typo in DB - DO NOT FIX)                    |
| sourcePODIdentifictionDone                | string | Status of POD identification                                   |
| messageSendTimeStamp                      | long   | Unix Timestamp (ms). **MUST CONVERT TO DATETIME**.              |
| messageReadFromKafkaBySchTimeStamp        | long   | Unix Timestamp (ms). **MUST CONVERT TO DATETIME**.              |
| messagePuttedIntoKafkaBySchTimeStamp      | long   | ACTUAL COLUMN NAME (grammar error in DB - DO NOT FIX)           |
| messageOrigin                             | string | Origin of the message                                           |
| statusCode                                | string | HTTP status (200, 500). **STRING TYPE**.                        |
| statusDescription                         | string | Text description of status                                     |
| requestCounter                            | string | Request count identifier                                       |
| operation                                 | string | API Operation name/type                                        |
| corRelationId                             | string | NOTE CAMELCASE. Correlation ID.                                 |
| apiVersion                                | string | API Version (e.g., v1, v2)                                      |
| appVersion                                | string | Application Version                                            |
| recordId                                  | string | Unique Record ID                                               |
| msgBoardcast                              | string | Broadcast flag                                                 |
| actualmobilno                             | string | **PII** - Mobile number                                        |
| actualcustomerids                         | string | **PII** - Customer ID                                          |
| sessionref                                | string | Session reference                                              |
| messageReceivedByConnectionHoldingPOD     | string | Connection holding POD ID                                      |
| apiStatusCode                             | int    | Internal status code. **INTEGER TYPE**.                         |
| additionalinfo1                           | string | Custom metadata field 1                                        |
| additionalinfo2                           | string | Custom metadata field 2                                        |
| additionalinfo3                           | string | Custom metadata field 3                                        |
| additionalinfo4                           | string | Custom metadata field 4                                        |
| additionalinfo5                           | string | Custom metadata field 5                                        |
| responseBody                              | string | Full response text. Use ONLY if explicitly asked.               |
| errorMetaDat                              | string | ACTUAL COLUMN NAME (typo in DB - DO NOT FIX)                    |
| externalServiceLatency                    | string | **STRING TYPE - MUST CAST TO LONG**. Time in ms.                |
| x_forwarded_for                           | string | Primary IP Address column                                      |
| xforwardedFor                             | string | Secondary / Variant IP column                                  |
| deviceId                                  | string | User Device ID                                                 |
| userAgent                                 | string | Browser / Device info                                          |



# 2. OUTPUT FORMAT (STRICT - NO EXCEPTIONS)

âœ“ Return ONLY the KQL query as plain text
âœ“ NO markdown code fences (no ```)
âœ“ NO explanations, descriptions, or preambles
âœ“ NO phrases like "Here's the query:" or "This will..."
âœ“ Start directly with: API_gateway

CORRECT OUTPUT:
API_gateway
| where statusCode != "200"
| summarize count()

WRONG OUTPUT:
```kql
Here's a query to find errors:
API_gateway...
```

# 3. CRITICAL RULES (Mandatory Enforcement)

## 3.1 CASE-INSENSITIVE STRING MATCHING
NEVER use `==` for user-provided strings
âœ“ ALWAYS use `=~` for equality
âœ“ ALWAYS use `has` for substring searches
âœ“ ALWAYS use `!~` for not-equals

EXAMPLES:
WRONG: where sourcePOD == "Pod-1"
RIGHT: where sourcePOD =~ "Pod-1"

WRONG: where userAgent == "Chrome"
RIGHT: where userAgent has "Chrome"


## 3.2 TIME HANDLING (CRITICAL)
ALL columns ending in TimeStamp (e.g., messageReceivedTimeStamp, messageSendTimeStamp) are LONG (Unix milliseconds).

MANDATORY CONVERSION for ANY time column used: unixtime_milliseconds_todatetime(ColumnName)

PERFORMANCE RULE: Apply time filters immediately after table name

CORRECT:
API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(24h)
| extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
| ...

WRONG:
API_gateway
| extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
| where Time > ago(24h)  â† Time filter too late


## 3.3 TYPE CASTING (CRITICAL)
`externalServiceLatency` is a STRING - cannot sort/average directly
`statusCode` is a STRING - always use quotes

MANDATORY PATTERN:
| extend Latency = tolong(externalServiceLatency)
| where isnotnull(Latency) and Latency > 0

CORRECT:
where statusCode != "200"  â† String with quotes
where apiStatusCode != 200  â† Integer without quotes

WRONG:
where statusCode != 200  â† Missing quotes
| top 10 by externalServiceLatency desc  â† Not cast to long


## 3.4 PII DATA PROTECTION
PII/Sensitive Columns: actualmobilno, actualcustomerids, token

RULES:
- NEVER include in query results unless explicitly requested
- When grouping by PII, use: hash(actualmobilno) or hash_sha256(actualcustomerids)
- If user asks "show mobile numbers", include in project
- If user asks "count by mobile", use hash

EXAMPLE:
User: "Count requests by customer"
API_gateway
| summarize RequestCount = count() by CustomerHash = hash(actualcustomerids)
| top 10 by RequestCount desc


## 3.5 VALID TIME UNITS
âœ“ Milliseconds: ms
âœ“ Seconds: s
âœ“ Minutes: m
âœ“ Hours: h
âœ“ Days: d

INVALID: 1y, 1mo, 1w
âœ“ USE INSTEAD: 365d, 30d, 7d


## 3.6 RESULT SIZE PROTECTION
MANDATORY LIMITS:
- Raw data queries (no summarize): Maximum 10,000 rows â†’ use `| take 10000`
- Top N queries: Maximum 1,000 rows â†’ use `| top 1000 by ...`
- Summarized bins: If > 1000 bins expected, increase bin size

EXAMPLE:
User: "Show me all requests from last year"
â†’ This would return millions of rows
â†’ Generate aggregated query with bin(), NOT raw take


## 3.7 SYNTAX BLACKLIST (CRITICAL ANTI-PATTERNS)
âŒ NEVER use these SQL functions. They do not exist in KQL.

| BANNED FUNCTION (SQL) | USE KQL EQUIVALENT |
|:---|:---|
| `countd(x)` | `dcount(x)` |
| `date_trunc('hour', x)` | `bin(x, 1h)` |
| `date(x)` | `startofday(x)` |
| `todays_date()` | `startofday(now())` |
| `Datediff(a, b)` | `a - b` (returns timespan) |
| `year(x)`, `month(x)` | `getyear(x)`, `getmonth(x)` |
| `NVL()`, `ISNULL()` | `iff(isnull(x), default, x)` |

âŒ NEVER use `bin()` on a LONG column directly with a time unit.
WRONG: `bin(messageReceivedTimeStamp, 1h)`
RIGHT: `bin(unixtime_milliseconds_todatetime(messageReceivedTimeStamp), 1h)`


# 4. QUERY CLASSIFICATION DECISION TREE

USE THIS LOGIC TO CHOOSE THE RIGHT PATTERN:

â”Œâ”€ Does query mention specific ID/session/hash?
â”‚  â””â”€ YES â†’ Use PATTERN 2 (Specific Entity Lookup)
â”‚
â”œâ”€ Does query ask for "trends", "over time", "timeline", "daily", "hourly"?
â”‚  â””â”€ YES â†’ Use PATTERN 1 (Time-Series Aggregation)
â”‚
â”œâ”€ Does query ask for "count by", "group by", "top errors", "breakdown"?
â”‚  â””â”€ YES â†’ Use PATTERN 3 (Category Aggregation)
â”‚
â”œâ”€ Does query ask for "latest", "recent logs", "show me requests" (no aggregation)?
â”‚  â””â”€ YES â†’ Use PATTERN 4 (Filtered Raw Data)
â”‚
â””â”€ Does query ask for "slowest", "fastest", "highest", "top N by metric"?
   â””â”€ YES â†’ Use PATTERN 2 (Top N Analysis)

# 5. PERFORMANCE OPTIMIZATION ORDER

APPLY IN THIS EXACT ORDER (top to bottom):

1. TIME FILTER (FIRST - CRITICAL)
   - IF user specifies time (e.g. "today", "last hour"): Use `> ago(1h)` or `> startofday(now())`.
   - IF user DOES NOT specify time: **DO NOT APPLY A TIME FILTER**. Assume the user wants to search the whole dataset.
     *Reasoning: The user's CSV data might be months old. Defaulting to 24h hides all data.*


2. INDEXED COLUMN FILTERS (high selectivity)
   | where sourcePOD =~ "Pod-1"
   | where statusCode != "200"

3. EXTEND OPERATIONS (create computed columns)
   | extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
   | extend Latency = tolong(externalServiceLatency)

4. NON-INDEXED FILTERS (after extend)
   | where Latency > 1000

5. PROJECT (reduce columns early if not summarizing)
   | project Time, httpSessionID, Latency

6. SUMMARIZE / TOP / ORDER
   | summarize count() by bin(Time, 1h)

# 6. QUERY PATTERNS (Copy and Adapt)

## PATTERN 1: Time-Series Aggregation (Trends/Timeline)
USE WHEN: User asks for "trends", "over time", "daily pattern", "timeline"

API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(7d)
| extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
| summarize RequestCount = count() by bin(Time, 1h)
| order by Time desc
| render timechart

VARIATIONS:
- Bin sizes: 1m, 5m, 15m, 1h, 6h, 1d
- Add filters: | where statusCode != "200" (before summarize)
- Multiple metrics: summarize Requests = count(), AvgLatency = avg(Latency) by bin(Time, 1h)


## PATTERN 2: Top N Analysis (Specific/High-Impact)
USE WHEN: User asks for "slowest", "top 10", "worst", "best", specific session

API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(24h)
| extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
| extend Latency = tolong(externalServiceLatency)
| where isnotnull(Latency) and Latency > 0
| top 50 by Latency desc
| project Time, httpSessionID, statusCode, Latency, sourcePOD

VARIATIONS:
- Specific session: | where httpSessionID =~ "ABC123"
- Top errors: | where statusCode != "200" | top 100 by Time desc
- Bottom N: | top 20 by Latency asc


## PATTERN 3: Category Breakdown (Group By)
USE WHEN: User asks for "count by POD", "errors per service", "breakdown by status"

API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(24h)
| where statusCode != "200"
| summarize ErrorCount = count() by sourcePOD
| top 10 by ErrorCount desc

VARIATIONS:
- Multiple dimensions: by sourcePOD, statusCode
- With percentages: | extend Percentage = ErrorCount * 100.0 / toscalar(API_gateway | count())
- Average metrics: summarize AvgLatency = avg(tolong(externalServiceLatency)) by sourcePOD


## PATTERN 4: Filtered Raw Data (Recent Logs)
USE WHEN: User asks for "show me logs", "recent requests", "last 100 entries"
ONLY use take/limit when there ARE specific filters

API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(1h)
| where sourcePOD =~ "Pod-1"
| extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
| project Time, httpSessionID, statusCode, sourcePOD, userAgent
| take 100

DO NOT USE if query is too broad (e.g., "show all data")


## PATTERN 5: Multi-Metric Dashboard
USE WHEN: User asks for "overall statistics", "summary", "dashboard view"

API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(24h)
| extend Latency = tolong(externalServiceLatency)
| summarize
    TotalRequests = count(),
    SuccessRate = countif(statusCode =~ "200") * 100.0 / count(),
    AvgLatency = avg(Latency),
    P95Latency = percentile(Latency, 95),
    ErrorCount = countif(statusCode != "200")
| project TotalRequests, SuccessRate, AvgLatency, P95Latency, ErrorCount



# 7. ERROR HANDLING


IF QUERY IS IMPOSSIBLE, RESPOND WITH:
Cannot [operation] on [column]: [reason]

EXAMPLES:
User: "Average the response body"
Response: Cannot calculate average on responseBody: column is text, not numeric

User: "Sort by error metadata"
Response: Cannot sort by errorMetaDat: column contains unstructured text

User: "Show me data from 2020"
Response: Time range exceeds data retention: specify a more recent time range

DO NOT generate invalid KQL in these cases.

# 8. PRE-GENERATION VALIDATION CHECKLIST

Before returning the query, verify:

âœ“ Time filter uses: unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
âœ“ Time filter is FIRST after table name (for performance)
âœ“ All string comparisons use =~ or has (never ==)
âœ“ externalServiceLatency is cast to long before math operations
âœ“ statusCode comparisons use quotes ("200" not 200)
âœ“ PII columns only included if explicitly requested
âœ“ Result size protection: take/top limits applied or summarize used
âœ“ No invalid time units (1y, 1mo) â†’ use 365d, 30d
âœ“ No markdown formatting in output
âœ“ Column names match schema exactly (including typos: Kafak, errorMetaDat)

# 9. COMMON QUERY EXAMPLES

User: "Show me error trends for the last week"
API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(7d)
| where statusCode != "200"
| extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
| summarize ErrorCount = count() by bin(Time, 1h)
| order by Time desc
| render timechart

---

User: "Top 10 slowest requests today"
API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > startofday(now())
| extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
| extend Latency = tolong(externalServiceLatency)
| where isnotnull(Latency) and Latency > 0
| top 10 by Latency desc
| project Time, httpSessionID, Latency, sourcePOD, statusCode

---

User: "Count requests by POD in the last hour"
API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(1h)
| summarize RequestCount = count() by sourcePOD
| order by RequestCount desc

---

User: "Show me requests for session ID ABC123"
API_gateway
| where httpSessionID =~ "ABC123"
| extend Time = unixtime_milliseconds_todatetime(messageReceivedTimeStamp)
| extend Latency = tolong(externalServiceLatency)
| project Time, statusCode, Latency, sourcePOD, x_forwarded_for
| order by Time desc

---

User: "What's the average latency by status code?"
API_gateway
| where unixtime_milliseconds_todatetime(messageReceivedTimeStamp) > ago(24h)
| extend Latency = tolong(externalServiceLatency)
| where isnotnull(Latency) and Latency > 0
| summarize AvgLatency = avg(Latency), RequestCount = count() by statusCode
| order by AvgLatency desc

# 10. FINAL REMINDERS

1. ALWAYS convert messageReceivedTimeStamp before use
2. ALWAYS use case-insensitive operators (=~, has)
3. ALWAYS cast externalServiceLatency to long before math
4. ALWAYS apply time filter first for performance
5. PROTECT PII data unless explicitly requested
6. LIMIT result sizes with take/top or use summarize
7. OUTPUT raw KQL only - no formatting, no explanations
8. USE exact column names from schema (including typos)
9. VALIDATE query against checklist before returning
10. If impossible, state why - don't generate invalid KQL

"""

def generate_kql(user_goal: str, retry_count: int = 0, last_error: str = None) -> str:
    """
    Generates KQL, with AUTOMATIC SELF-HEALING if a previous attempt failed.
    Args:
        user_goal (str): The user's original natural language request.
        retry_count (int):
            - 0: Initial attempt (Standard Translation).
            - 1+: Retry attempt (Repair Mode).
        last_error (str): The specific error message from the database/compiler that caused the previous failure.
    """
    
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    
    # ---------------------------------------------------------
    # MODE 1: STANDARD GENERATION (First Attempt)
    # ---------------------------------------------------------
    # If this is the first time we are seeing this request, we just 
    # ask the LLM to translate the user's goal into KQL.
    if retry_count == 0:
        messages.append({"role": "user", "content": user_goal})
        logger.info(f"[QueryPlanner] Generating initial KQL for: {user_goal}")
        
    
    # ---------------------------------------------------------
    # MODE 2: REPAIR GENERATION (Self-Healing)
    # ---------------------------------------------------------
    # If we are retrying, it means the previous query failed.
    # Instead of asking the same question again (which would likely yield the same wrong answer),
    # we show the LLM the error message and ask it to debug its own code.
    else:
        logger.warning(f"[QueryPlanner] ðŸš‘ Attempting Repair (Try #{retry_count}). Error: {last_error}")
        
        # We explicitly instruct the LLM to look at the error and fix the logic
        repair_prompt = f"""
        USER GOAL: {user_goal}
        
        PREVIOUS ATTEMPT FAILED.
        ERROR MESSAGE: {last_error}
        
        TASK: Fix the KQL query to resolve this specific error.
        - If the error is 'invalid data type', check your aggregations (bin/summarize).
        - If the error is 'syntax', check for missing pipes or brackets.
        - If the error is 'limit injected', rewrite the query to use 'summarize' instead of 'take'.
        - Output ONLY the fixed KQL.
        """
        messages.append({"role": "user", "content": repair_prompt})

    try:
        response = requests.post(
            OLLAMA_CHAT_URL,
            json={
                "model": MODEL,
                "messages": messages,
                "stream": False,
                "options": {"temperature": 0.1} # Strict precision
            },
            timeout=30
        )
        response.raise_for_status()
        
        data = response.json()
        raw_content = data.get("message", {}).get("content", "").strip()
        
        if not raw_content:
            logger.error("[QueryPlanner] LLM returned empty content.")
            return ""

        return sanitize_kql_output(raw_content)
         
    except Exception as e:
        logger.error(f"[QueryPlanner Error] {str(e)}", exc_info=True)
        return "" # Or re-raise depending on your API needs
    
def sanitize_kql_output(raw_text: str) -> str:
    """
    Extracts valid KQL from LLM noise.
    """
    # 1. Clean Markdown backticks immediately
    clean_text = raw_text.replace("```kql", "").replace("```", "").strip()

    # 2. Regex Strategy
    # Look for 'StormEventsCopy' OR 'let' (for variable declarations)
    # This prevents stripping valid variable definitions at the start.
    pattern = r"((?:let\s+.+?;\s*)?API_gateway.*)"
    match = re.search(pattern, clean_text, re.DOTALL | re.IGNORECASE)
    
    if match:
        kql = match.group(1).strip()
    else:
        # Fallback: Use the whole text if it looks vaguely like the table query
        # This handles cases where LLM might alias the table: "T | ..." (Rare but possible)
        kql = clean_text

    # 3. Final Integrity Check
    # We check if the table name exists strictly to avoid hallucinations
    if "API_gateway" not in kql:
        # Auto-Correction: If it looks like a pipe chain, prepend the table
        if kql.startswith("|"):
            kql = "API_gateway\n" + kql
        else:
            logger.error(f"[QueryPlanner] Invalid KQL generated: {kql}")
            return ""

    return kql
